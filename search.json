[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blueprint Big Book of Data Analysis",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "wf.html#why-workflow",
    "href": "wf.html#why-workflow",
    "title": "Workflow",
    "section": "Why Workflow?",
    "text": "Why Workflow?\nBlueprint’s data analysts have built tools and practices that suit their various needs. As a collective, we do data analysis well in the status quo model. Why establish standards for organizing and executing data analysis projects? Because we think that the whole process of data analysis could be easier to do, easier to learn, more predictable for managers, more collaborative for data goblins, and make more contributions to our collective intelligence as a community of practice."
  },
  {
    "objectID": "wf.html#recommended-reading",
    "href": "wf.html#recommended-reading",
    "title": "Workflow",
    "section": "Recommended Reading",
    "text": "Recommended Reading\nThroughout this section, we make reference to a number of resources created by the R development and data analysis community. Each is a worthwhile read in its own right, and we recommend that you check them out at some point.\n\nBryan, J. Happy Git and GitHub for the useR\nThe ur-text for R users looking to integrate git and Github into their analysis workflows. Bryan keeps it fun and friendly while providing a thorough introduction to the nuts and bolts of getting started. Closer to required than recommended reading.\n\n\nWickham, H. R for Data Science\nHadley is the GOAT R developer, and this book – while a bit sparse and introductory – offers valuable advice and instruction across the whole process, with some starting points for analysis workflow.\n\n\nGit Commands Cheatsheet\nGit can do many different things, and so comes with many different commands. This is a fairly comprehensive reference. Use it if you know what you want to do, you know git can do it, but you’re just not sure which command will make it happen."
  },
  {
    "objectID": "wf-git.html#why-git-and-github",
    "href": "wf-git.html#why-git-and-github",
    "title": "2  Git and Github",
    "section": "2.1 Why Git and Github?",
    "text": "2.1 Why Git and Github?\nIn 2017, Jennifer Bryan expanded on the ‘Why Git?’ chapter of her invaluable instructional book in the paper Excuse me, do you have a moment to talk about version control?. She articulates the benefits so clearly that they are not worth rephrasing:\n\nDoing your work becomes tightly integrated with organizing, recording, and disseminating it. It’s not a separate, burdensome task you are tempted to neglect.\nCollaboration is much more structured, with powerful tools for asynchronous work and managing versions.\nThe marginal effort required to create a web presence for a project is negligible.\nBy using common mechanics across work modes (research, teaching, analysis), you achieve basic competence quickly and avoid the demoralizing forget-relearn cycle.\n\nIf you have worked on a data analysis project at Blueprint, particularly one that involves collaboration, you have undoubtedly done the following:\n\nSearching for an explanation about when or why a specific choice about processing the data was made\nExperienced disorientation attempting to navigate someone else’s code\nSpent hours undoing a change that breaks the pipeline\nWanted someone’s help or advice about how to solve a problem, but didn’t feel like it would be worth getting them access\n\nHosted version control like Github empowers you with tools to simplify and routinize any of these situations."
  },
  {
    "objectID": "wf-git.html#gitting-rolling",
    "href": "wf-git.html#gitting-rolling",
    "title": "2  Git and Github",
    "section": "2.2 Gitting rolling",
    "text": "2.2 Gitting rolling\nAt a minimum, you’ll need to install git and register a Github account. Optionally, you can also integrate git and Github into your RStudio environment. If you’ve done those things already, great, you’re good to go! Otherwise, it is strongly recommended that you pause what you’re doing now and read / work through Happy Git before continuing."
  },
  {
    "objectID": "wf-git.html#usage-at-blueprint-as-of-may-2023",
    "href": "wf-git.html#usage-at-blueprint-as-of-may-2023",
    "title": "2  Git and Github",
    "section": "2.3 Usage at Blueprint (as of May 2023)",
    "text": "2.3 Usage at Blueprint (as of May 2023)\nRight now, usage is highly varied. Some members of the Data Lab team use git and Github for version control and hosting of both R packages and analysis project code. It is not, however, part of the typical analysis project. We will begin rolling out the basic workflow in the summer of 2023 and see how it goes."
  },
  {
    "objectID": "wf-structure.html#a-conceptual-skeleton",
    "href": "wf-structure.html#a-conceptual-skeleton",
    "title": "3  Folder Structure",
    "section": "3.1 A Conceptual Skeleton",
    "text": "3.1 A Conceptual Skeleton\nThe diagram below presents a basic revision of the aforementioned structure. The two substantial differences are:\n\nrather than living within the same folder, data and code live in different places. Data stay in the project’s Z drive folder; code, outputs, figures in the analysis repo (folder).\nthe project’s analysis repo is versioned with git and reflected in a remote repo hosted on GitHub\n\n\n\n\n\nflowchart LR\n    P(Project Library)\n    MP(My Project)\n    D[Intranet folder including \\nDeliverables, Admin docs, etc.]\n    P --- MP\n    MP --- D\n    Z(Z-drive)\n    MZ(My Project)\n    S[Encrypted data folder including\\nSurvey Exports, Program Data, etc.]\n    Z --- MZ\n    MZ --- S\n    L(my-project)\n    ML(My Laptop)\n    C[local git repository, containing\\nCode, reports, figures]\n    ML --- L\n    L --- C\n    GH(Github)\n    R(my-username/my-project)\n    CR[remote git repository\\nreflecting its local counterpart]\n    GH --- R\n    R --- CR\n\n\n\n\n\nThis concept intentionally leaves the substructure of the data folder Z:/My Project and the analysis repo My Laptop/my-project up to the judgement and preference of the project’s specific team. The key difference from the typical current structure is strictly that data (and only data) live in the Z-drive.\n\n\n\n\n\n\nGuidance and tools for setting up analysis repos according to your needs is forthcoming, but it will be in a different section."
  },
  {
    "objectID": "wf-structure.html#what-else-is-new",
    "href": "wf-structure.html#what-else-is-new",
    "title": "3  Folder Structure",
    "section": "3.2 What else is new?",
    "text": "3.2 What else is new?\nLocating analysis code and outputs outside of the Z-drive entails some considerations and requirements that were previously irrelevant:\n\nRemote analysis repositories (GitHub) should be set to private before any outputs are generated. Any colleagues who need to see the code should be invited to collaborate.\nPaths to data files used in code will need to be “hard-coded”, meaning that they will need to begin with “Z:/My Project/”. We’re working on ways to make this easier and more flexible, but hard-coding (in this case) will definitely work.\nBecause files and folders in Z:/My Project will be referred to directly, the names of and paths to files and folders in Z:/My Project should, unless absolutely necessary, be left unchanged from the time that they are created.\nEnsure that outputs (reports, figures, tables) don’t include any personal identifying information. While they won’t be available to the general public in a private Github repo, our policy is to confine such sensitive information to our Z-drive."
  },
  {
    "objectID": "wf-basic.html#creating-an-analysis-repo",
    "href": "wf-basic.html#creating-an-analysis-repo",
    "title": "4  Basic Workflow",
    "section": "4.1 Creating an Analysis Repo",
    "text": "4.1 Creating an Analysis Repo\nAn analysis repo is basically just an R project. You can set one up through the RStudio GUI, or with the usethis package. usethis also includes handy helpers for initializing a repository, so I tend to rely on it for each step.\nusethis::create_project(\"my-project\")\nThen, open the project folder in your development environment (RStudio or VSCode), and run the following in your R console1.\nusethis::use_git()\nusethis::use_github(private = TRUE)\nAssuming you have set up your Github credentials, your analysis repo will be up and running locally and remotely."
  },
  {
    "objectID": "wf-basic.html#narrowing-the-scope",
    "href": "wf-basic.html#narrowing-the-scope",
    "title": "4  Basic Workflow",
    "section": "4.2 Narrowing the scope",
    "text": "4.2 Narrowing the scope\nAs mentioned previously, git can do a lot. For this basic workflow, you’re only going to use three commands to make it run: git add git commit and git push. We assume you’re the only one working on the analysis repo. If you are collaborating with others, and especially if you are working on different aspects of the project at the same time, please reach out for more guidance if you’re feeling unsure."
  },
  {
    "objectID": "wf-basic.html#the-basic-pattern",
    "href": "wf-basic.html#the-basic-pattern",
    "title": "4  Basic Workflow",
    "section": "4.3 The Basic Pattern",
    "text": "4.3 The Basic Pattern\n\nIdentify a task (like “link survey data”, “clean program records”, “explore demographics”)\nWrite the code that completes the task (you’ve been here before)\ngit add -A to stage your changes to the analysis repo\ngit commit -m \"link survey data\" 2 to commit your changes with the message “link survey data” (use whatever task you’re actually doing)\ngit push -u origin main to upload your local changes to the remote (github) repository.\n\nThis basic pattern is a simplified version of the Repeated Amend workflow pattern described in Happy Git. You’re welcome to use that pattern as well, or explore Branching and Merging."
  },
  {
    "objectID": "wf-basic.html#what-can-i-do-now-that-i-couldnt-before",
    "href": "wf-basic.html#what-can-i-do-now-that-i-couldnt-before",
    "title": "4  Basic Workflow",
    "section": "4.4 What can I do now that I couldn’t before?",
    "text": "4.4 What can I do now that I couldn’t before?\n\nAsk for help: if you’ve run into a problem that you don’t feel equipped to solve, you can ask one of your colleagues (with access to the Z-drive data folder) to clone the analysis repo, run your code, and offer edits, advice, or whatever else would help.\nShow your work: the analysis repo is less sensitive than the data folder, and so can be shown to any Blueprinter, whether they are on the project team or not.\nFind solutions: get inspiration from other data analyzing printers using the same approach by borrowing their code."
  },
  {
    "objectID": "wf-basic.html#footnotes",
    "href": "wf-basic.html#footnotes",
    "title": "4  Basic Workflow",
    "section": "",
    "text": "The R console, where you execute R commands, is not the same as the Terminal (a.k.a. Shell, Command Prompt) You may not have used the terminal before, but you should be able to access it within your RStudio interface. See again Happy Git for more detail.↩︎\nDo your best to include a commit message every time you make a commit. Git requires that every commit have an accompanying message, and if you don’t provide in the shell directly, it will send you to vim, a much more confusing program.↩︎"
  },
  {
    "objectID": "wf-goal.html",
    "href": "wf-goal.html",
    "title": "5  Advanced / Aspirational Workflow",
    "section": "",
    "text": "This section is still quite rough. If you’re here, you’re welcome to drop suggested changes, additions, or clarifications in the comments. Your input will be incorporated into the development process.\n\n\n\nBolded items are clear hooks for tools, rules, standards.\nAP[X] is the Xth analysis planning stage R[X] is the Xth artefact of the analysis process\n\nPre-contract\n\n\nProposal\nResearch objectives\nAP0: Preliminary plan\n\nR0: High-level methodology\n\n\n\nData design\n\n\nSurvey designs\nAdmin datasets\nAP1: Specify approach\n\nR1: Detailed methodology\nR2: Input data dictionary\n\n\n\nData collection\n\n\nMonitoring:\n\nR3: Monitoring log\n\n\n\nAnalyze\n\n\nHave the data for the analysis\nHave accumulated insights\nHave monitoring logs\nExplore loop:\n\nR4: Exploratory output pile\nR5: Decision log\n\nAP2: revisit R1: Detailed methodology\n\nRealign analysis objectives with project objectives\nAssess feasibility through exploration\nIdentify limitations and enumerate implications\nJustify methodological adapatations\nIteratively build R6: data pipeline\nDocument final data pipeline\nFinalize methodology\n\n\n\nPublish\n\n\nAP3: Schedule of deliverable outputs\n\nR7: Analysis outputs"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]